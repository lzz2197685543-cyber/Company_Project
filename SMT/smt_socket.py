import pprint

import requests
import time
import os
import csv
import json
from datetime import datetime
from logger_config import SimpleLogger


class SMT_Stock:
    def __init__(self, shop_name, cookie):
        self.shop_name = shop_name
        self.cookies = cookie
        self.logger = SimpleLogger(name='SMT_SOCKET')

        self.headers = {
            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36',
        }
        self.url = 'https://scm-supplier.aliexpress.com/aidc-aic-console/aic-inventory-manage/getRealTimeInvWithClearanceInfo'

        self.csv_headers = [
            'å¹³å°', 'åº—é“º', 'è´§å·ID', 'å•†å“åç§°', 'æŠ“å–æ•°æ®æ—¥æœŸ',
            'ä»Šæ—¥é”€é‡', 'è¿‘7å¤©é”€é‡', 'è¿‘30å¤©é”€é‡', 'å¹³å°åº“å­˜', 'åœ¨é€”åº“å­˜'
        ]

        self.data_dir = "./data/data"
        self._make_data_dir()

    def _make_data_dir(self):
        """åˆ›å»ºæ•°æ®ç›®å½•"""
        if not os.path.exists(self.data_dir):
            try:
                os.makedirs(self.data_dir)
                self.logger.info(f"åˆ›å»ºç›®å½•: {self.data_dir}")
            except Exception as e:
                self.logger.error(f"åˆ›å»ºç›®å½•å¤±è´¥: {e}")
                raise

    def _get_filename(self):
        """ç”ŸæˆCSVæ–‡ä»¶å"""
        current_date = datetime.now().strftime("%Y%m%d")
        return f"./data/data/{self.shop_name}_stock_{current_date}.csv"

    def _make_request(self, page, test_mode=False):
        """å‘èµ·HTTPè¯·æ±‚è·å–æ•°æ®"""
        payload = {
            'groupDimension': 0,
            'stockingMode': 'WAREHOUSE',
            'pageIndex': page,
            'pageSize': 50,
            '_scm_token_': 'lz4vmSbNuZUqpDDIF-wUzjicndw',
        }

        try:
            self.headers.update({'Cookie': self.cookies})
            response = requests.post(
                url=self.url,
                headers=self.headers,
                json=payload,
                timeout=30
            )

            self.logger.info(f"ç¬¬{page}é¡µå“åº”çŠ¶æ€ç : {response.status_code}")

            if test_mode:
                result = {
                    'status_code': response.status_code,
                    'success': response.status_code == 200
                }
                if response.status_code == 200:
                    try:
                        result['json_data'] = response.json()
                    except:
                        result['json_data'] = None
                return result

            if response.status_code == 200:
                return response.json()
            elif response.status_code == 403:
                self.logger.error("è®¿é—®è¢«æ‹’ç» (403)ï¼Œå¯èƒ½æ˜¯cookieå¤±æ•ˆ")
                return None
            else:
                self.logger.error(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                return None

        except requests.exceptions.RequestException as e:
            self.logger.error(f"ç¬¬{page}é¡µè¯·æ±‚å¤±è´¥: {e}")
            return None
        except Exception as e:
            self.logger.error(f"ç¬¬{page}é¡µå‘ç”Ÿé”™è¯¯: {e}")
            return None

    def _extract_item(self, item_data):
        """æå–å•ä¸ªå•†å“æ•°æ®"""
        try:
            return {
                'å¹³å°': 'é€Ÿå–é€š',
                'åº—é“º': self.shop_name,
                'è´§å·ID': item_data['scItemInfo']['scItemId'],
                'å•†å“åç§°': item_data['scItemInfo']['scItemName'],
                'æŠ“å–æ•°æ®æ—¥æœŸ': int(time.time()*1000),
                'ä»Šæ—¥é”€é‡': item_data['saleInfo'][0]['value'],
                'è¿‘7å¤©é”€é‡': item_data['saleInfo'][1]['value'],
                'è¿‘30å¤©é”€é‡': item_data['saleInfo'][3]['value'],
                'å¹³å°åº“å­˜': item_data['warehouseQuantityLabelInfo'][0]['value'],
                'åœ¨é€”åº“å­˜': int(item_data['onWayQuantityLabelInfo'][0]['value'])
            }
        except (KeyError, IndexError) as e:
            self.logger.error(f"æ•°æ®å­—æ®µé”™è¯¯: {e}")
            return None

    def _parse_data(self, json_data):
        """è§£æAPIå“åº”æ•°æ®"""
        if not json_data or 'data' not in json_data:
            self.logger.warning("æ— æœ‰æ•ˆæ•°æ®")
            return []

        items = json_data.get('data', [])
        if not items:
            return []

        parsed_items = []
        for item in items:
            parsed_item = self._extract_item(item)
            if parsed_item:
                parsed_items.append(parsed_item)

        return parsed_items

    def _save_data(self, items):
        """ä¿å­˜æ•°æ®åˆ°CSV"""
        if not items:
            return

        filename = self._get_filename()
        file_exists = os.path.exists(filename)

        try:
            with open(filename, 'a', encoding='utf-8-sig', newline='') as f:
                writer = csv.DictWriter(f, fieldnames=self.csv_headers)

                if not file_exists:
                    writer.writeheader()

                writer.writerows(items)

            self.logger.info(f"å·²ä¿å­˜{len(items)}æ¡æ•°æ®åˆ°æ–‡ä»¶: {filename}")
        except Exception as e:
            self.logger.error(f"ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")

    def _get_page_data(self, page, max_retries=3):
        """è·å–å•ä¸ªé¡µé¢æ•°æ®ï¼ŒåŒ…å«é‡è¯•"""
        self.logger.info(f'æ­£åœ¨çˆ¬å–ç¬¬{page}é¡µçš„æ•°æ®')

        for retry in range(max_retries):
            data = self._make_request(page)

            if data is not None:
                return data

            if retry < max_retries - 1:
                self.logger.info(f"ç¬¬{retry + 1}æ¬¡é‡è¯•...")
                time.sleep(2)

        self.logger.error(f"ç¬¬{page}é¡µé‡è¯•{max_retries}æ¬¡åä»ç„¶å¤±è´¥")
        return None

    def run(self):
        """ä¸»è¿è¡Œå‡½æ•°"""
        self.logger.info(f"ğŸš€ å¼€å§‹çˆ¬å– {self.shop_name} çš„åº“å­˜æ•°æ®")

        page = 1
        total_items = 0
        page_size = 50

        while True:
            # è·å–é¡µé¢æ•°æ®
            json_data = self._get_page_data(page)
            if json_data is None:
                break

            # è§£ææ•°æ®
            items = self._parse_data(json_data)
            if not items:
                self.logger.info('æ²¡æœ‰æ›´å¤šæ•°æ®äº†')
                break

            # ä¿å­˜æ•°æ®
            self._save_data(items)

            # æ›´æ–°ç»Ÿè®¡
            current_count = len(items)
            total_items += current_count
            self.logger.info(f"ç¬¬{page}é¡µå¤„ç†å®Œæˆï¼Œç´¯è®¡å¤„ç†: {total_items}æ¡")

            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ä¸‹ä¸€é¡µ
            if current_count < page_size:
                self.logger.info('å·²åˆ°è¾¾æœ€åä¸€é¡µ')
                break

            page += 1
            time.sleep(1)

        self.logger.info(f"âœ… {self.shop_name} åº“å­˜æ•°æ®çˆ¬å–å®Œæˆï¼å…±è·å–{total_items}æ¡æ•°æ®")
        return total_items




if __name__ == '__main__':
    # åº—é“ºåˆ—è¡¨
    shop_names = ['SMT202', 'SMT214', 'SMT212', 'SMT204', 'SMT203', 'SMT201', 'SMT208']
    # shop_names = ['SMT002']
    # åŠ è½½cookies
    cookies_file = './data/socket_cookies.json'
    """ä»æ–‡ä»¶åŠ è½½cookies"""
    try:
        with open(cookies_file, 'r', encoding='utf-8') as f:
             all_cookies=json.load(f)
    except Exception as e:
        print(f'åŠ è½½cookieså¤±è´¥---åº”è¯¥æ²¡æœ‰cookieæ–‡ä»¶')

    if not all_cookies:
        print("âŒ æ— æ³•åŠ è½½cookiesï¼Œç¨‹åºé€€å‡º")
        exit(1)

    # éå†æ‰€æœ‰åº—é“º
    for shop_name in shop_names:
        print(f"\n{'=' * 50}")
        print(f"å¤„ç†åº—é“º: {shop_name}")
        print(f"{'=' * 50}")

        if shop_name not in all_cookies:
            print(f"âŒ åº—é“º {shop_name} çš„cookieä¸å­˜åœ¨ï¼Œè·³è¿‡")
            continue

        try:
            crawler = SMT_Stock(shop_name, all_cookies[shop_name])
            count = crawler.run()
            print(f"âœ… {shop_name}: æˆåŠŸçˆ¬å– {count} æ¡æ•°æ®")
        except Exception as e:
            print(f"âŒ {shop_name}: çˆ¬å–å¤±è´¥ - {e}")
            continue