import json
import asyncio
import requests
from utils.cookie_manager import CookieManager
import time
from pathlib import Path
from datetime import datetime
import csv
from utils.logger import get_logger

class SMTStockSpider:
    def __init__(self, shop_name: str,):
        self.shop_name = shop_name
        self.cookie_manager = CookieManager(shop_name)
        self.logger = get_logger(f"SMTGoods-{shop_name}")
        self.url = (
            "https://scm-supplier.aliexpress.com/"
            "aidc-aic-console/aic-inventory-manage/getRealTimeInvWithClearanceInfo"
        )
        self.headers = {
            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36',
        }

    # ---------- è¯·æ±‚ ----------
    def fetch_page(self, cookies,page_index: int):
        self.logger.info(f'æ­£åœ¨çˆ¬å–ç¬¬{page_index}é¡µ')
        """å‘èµ·HTTPè¯·æ±‚è·å–æ•°æ®"""
        payload = {
            'groupDimension': 0,
            'stockingMode': 'WAREHOUSE',
            'pageIndex': page_index,
            'pageSize': 50,
            '_scm_token_': 'lz4vmSbNuZUqpDDIF-wUzjicndw',
        }

        try:
            response = requests.post(
                url=self.url,
                headers=self.headers,
                cookies=cookies,
                json=payload,
                timeout=30
            )

            data=response.json()
            return data

        except Exception as e:
            self.logger.error(f'è¯·æ±‚å“åº”æ•°æ®å¤±è´¥:{e}')

    # ---------- è§£æ ----------
    def parse_page(self,json_data):
        items = []

        for i in json_data.get('data', []):
            try:
                item={
                    'å¹³å°': 'é€Ÿå–é€š',
                    'åº—é“º': self.shop_name,
                    'è´§å·ID': i['scItemInfo']['scItemId'],
                    'å•†å“åç§°': i['scItemInfo']['scItemName'],
                    'æŠ“å–æ•°æ®æ—¥æœŸ': int(time.time() * 1000),
                    'ä»Šæ—¥é”€é‡': i['saleInfo'][0]['value'],
                    'è¿‘7å¤©é”€é‡': i['saleInfo'][1]['value'],
                    'è¿‘30å¤©é”€é‡': i['saleInfo'][3]['value'],
                    'å¹³å°åº“å­˜': i['warehouseQuantityLabelInfo'][0]['value'],
                    'åœ¨é€”åº“å­˜': int(i['onWayQuantityLabelInfo'][0]['value'])
                }
                items.append(item)
            except Exception as e:
                self.logger.error('è§£ææ•°æ®æœ‰é—®é¢˜:{e}')

        return items

    def save_items(self, items):
        out_dir = Path(__file__).resolve().parent.parent / "data" / "result"
        self.logger.info(out_dir)
        out_dir.mkdir(parents=True, exist_ok=True)

        fname = out_dir / f"{self.shop_name}_stock_{datetime.now():%Y%m%d}.csv"
        exists = fname.exists()

        with open(fname, "a", newline="", encoding="utf-8-sig") as f:
            writer = csv.DictWriter(f, fieldnames= [
            'å¹³å°', 'åº—é“º', 'è´§å·ID', 'å•†å“åç§°', 'æŠ“å–æ•°æ®æ—¥æœŸ',
            'ä»Šæ—¥é”€é‡', 'è¿‘7å¤©é”€é‡', 'è¿‘30å¤©é”€é‡', 'å¹³å°åº“å­˜', 'åœ¨é€”åº“å­˜'
        ])
            if not exists:
                writer.writeheader()
            writer.writerows(items)


    async def run(self):
        self.logger.info(f'æ­£åœ¨çˆ¬å–åº—é“º-------{self.shop_name}------çš„æ•°æ®')

        page_index = 1
        cookies,token= await self.cookie_manager.get_auth()
        retry = False
        while True:
            #è¯·æ±‚å“åº”æ•°æ®
            json_data = self.fetch_page(cookies,page_index)

            # ---------- æ²¡æœ‰è·å–åˆ°æ­£ç¡®çš„æ•°æ®æˆ‘ä»¬åˆ¤æ–­cookie å¤±æ•ˆ ----------
            if not json_data or 'data' not in json_data:
                if retry:
                    raise RuntimeError("cookie åˆ·æ–°åä»ç„¶å¤±æ•ˆ")

                print(f"[{self.shop_name}] cookie å¤±æ•ˆï¼Œè‡ªåŠ¨é‡æ–°ç™»å½•ä¸­...")
                await self.cookie_manager.refresh()
                cookies, token = await self.cookie_manager.get_auth()

                retry=True  # retryä¸ºäº†é˜²æ­¢cookieä¸€ç›´å¤±æ•ˆè¿›å…¥æ­»å¾ªç¯
                continue  # ğŸ‘ˆ ç”¨æ–° cookie é‡è¯•å½“å‰é¡µï¼Œcontinue ä¼šè®©ç¨‹åºå›åˆ° while True çš„å¼€å¤´

            # è§£ææ•°æ®
            items=self.parse_page(json_data)
            self.logger.info(f'è§£æå¾—åˆ°{len(items)}æ¡æ•°æ®')

            # ä¿å­˜æ•°æ®
            self.save_items(items)
            self.logger.info(f'ç¬¬{page_index}é¡µï¼Œæ•°æ®ä¿å­˜æˆåŠŸ')

            if len(items)<50:
                self.logger.info('å·²ç»è¾¾åˆ°æœ€åä¸€é¡µäº†')
                break

            page_index += 1
            retry = False
            await asyncio.sleep(0.8)
