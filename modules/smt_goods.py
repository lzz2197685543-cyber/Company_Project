import json
import time
import csv
import hashlib
from datetime import datetime
from pathlib import Path
import requests

from utils.cookie_manager import CookieManager
from utils.logger import get_logger


class SMTGoodsSpider:
    def __init__(self, shop_name: str):
        self.shop_name = shop_name
        self.cookie_manager = CookieManager(shop_name)
        self.logger = get_logger(f"SMTGoods-{shop_name}")

        self.url = (
            "https://seller-acs.aliexpress.com/"
            "h5/mtop.ae.scitem.read.pagequery/1.0/"
        )
        self.headers = {
            "origin": "https://csp.aliexpress.com",
            "referer": "https://csp.aliexpress.com/",
            "user-agent": (
                "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                "AppleWebKit/537.36 (KHTML, like Gecko) "
                "Chrome/127.0.0.0 Safari/537.36"
            ),
        }

        self.total_pages = 1

    # ---------- ç­¾å ----------
    def make_sign(self, token, ts, app_key, data):
        text = f"{token}&{ts}&{app_key}&{data}"
        return hashlib.md5(text.encode()).hexdigest()

    # ---------- è¯·æ±‚ ----------
    def fetch_page(self, cookies, token, page):
        self.logger.info(f'å¼€å§‹çˆ¬å–ç¬¬{page}é¡µæ•°æ®')

        ts = int(time.time() * 1000)
        app_key = "30267743"
        channelId = self.cookie_manager.channel_id

        data_dict = {
            "pageIndex": page,
            "pageSize": 20,
            "channelId": f"{channelId}"
        }
        data_str = json.dumps(data_dict, separators=(",", ":"))

        sign = self.make_sign(token, ts, app_key, data_str)
        params = {
            'jsv': '2.7.2',
            'appKey': app_key,
            't': str(ts),
            'sign': sign,
            'v': '1.0',
            'timeout': '30000',
            'H5Request': 'true',
            'url': 'mtop.ae.scitem.read.pagequery',
            'params': '[object Object]',
            '__channel-id__': f'{channelId}',
            'api': 'mtop.ae.scitem.read.pagequery',
            'type': 'originaljson',
            'dataType': 'json',
            'valueType': 'original',
            'x-i18n-regionID': 'AE',
            'data': data_str,
        }

        try:

            resp = requests.post(
                self.url,
                cookies=cookies,
                headers=self.headers,
                params=params,
                timeout=15,
            )
            # print(resp.text)

            if resp.status_code != 200:
                return None

            result = resp.json()
        except Exception as e:
            self.logger.error(f'è¯·æ±‚å“åº”å¤±è´¥:{e}')


        # ğŸ‘‡ å…³é”®ï¼štoken / session å¤±æ•ˆåˆ¤å®š
        ret = result.get("ret", [])
        if ret and isinstance(ret, list):
            code = ret[0]
            if "FAIL_SYS_TOKEN" in code or "SESSION_EXPIRED" in code:
                return "COOKIE_EXPIRED"

        return result

    # ---------- è§£æ ----------
    def parse_page(self, data,page):
        if not data or "data" not in data:
            return []

        if "totalPages" in data["data"]:
            self.total_pages = data["data"]["totalPages"]
            print(f'æ€»å…±{self.total_pages}')

        items = []
        for i in data["data"].get("data", []):
            try:
                sku = ""
                if i.get("items"):
                    sku = i["items"][0].get("skuOuterId", "")

                items.append({
                    "è´§å·ID": i.get("scitemId"),
                    "sku": sku,
                })
            except Exception as e:
                self.logger.error(f'è§£ææ•°æ®å¤±è´¥:{e}')
        return items

    # ---------- ä¿å­˜ ----------
    def save_items(self, items):
        out_dir =Path(__file__).resolve().parent.parent / "data" / "result"
        out_dir.mkdir(parents=True, exist_ok=True)

        fname = out_dir / f"{self.shop_name}_goods_{datetime.now():%Y%m%d}.csv"
        exists = fname.exists()

        with open(fname, "a", newline="", encoding="utf-8-sig") as f:
            writer = csv.DictWriter(f, fieldnames=["è´§å·ID", "sku"])
            if not exists:
                writer.writeheader()
            writer.writerows(items)

    # ---------- ä¸»æµç¨‹ ----------
    async def run(self):
        self.logger.info(f'æ­£åœ¨çˆ¬å–åº—é“º------{self.shop_name}------çš„æ•°æ®')
        cookies, token = await self.cookie_manager.get_auth()

        page = 1
        retry = False

        while True:
            # è¯·æ±‚å“åº”æ•°æ®
            data = self.fetch_page(cookies, token, page)
            print(data)

            # ---------- cookie å¤±æ•ˆ ----------
            if data == "COOKIE_EXPIRED":
                if retry:
                    raise RuntimeError("cookie åˆ·æ–°åä»ç„¶å¤±æ•ˆ")

                self.logger.info(f"[{self.shop_name}] cookie å¤±æ•ˆï¼Œè‡ªåŠ¨é‡æ–°ç™»å½•ä¸­...")
                await self.cookie_manager.refresh()
                cookies, token = await self.cookie_manager.get_auth()

                retry = True  # retryä¸ºäº†é˜²æ­¢cookieä¸€ç›´å¤±æ•ˆè¿›å…¥æ­»å¾ªç¯
                continue  # ğŸ‘ˆ ç”¨æ–° cookie é‡è¯•å½“å‰é¡µï¼Œcontinue ä¼šè®©ç¨‹åºå›åˆ° while True çš„å¼€å¤´

            # è§£ææ•°æ®
            items = self.parse_page(data, page)


            self.save_items(items)

            self.logger.info(f"[{self.shop_name}] ç¬¬ {page} é¡µ {len(items)} æ¡---ä¿å­˜æˆåŠŸ")

            if page >= self.total_pages:
                print('æ•°æ®çˆ¬å–å®Œæ¯•')
                break

            page += 1
            retry = False
            time.sleep(1)

