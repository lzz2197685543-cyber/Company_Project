import asyncio
from services.site.site_skc_sku_violate import SkcFetcher
from services.site.sku_site_status import SkuSiteStatusFetcher
from services.site.sku_site_exception import SkuException
from utils.logger import get_logger
from utils.dingding_doc import DingTalkTokenManager, upload_multiple_records, test_delete_records
from utils.dingtalk_bot import ding_bot_send

from datetime import datetime,timedelta
from pathlib import Path
import pandas as pd
import time
import re
from typing import Dict, List, Tuple, Any

import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from services.site.site_skc_sku_violate import SkcFetcher

SITE_DIR = Path(__file__).resolve().parent.parent / "data" / "site"
SITE_DIR.mkdir(parents=True, exist_ok=True)

"""temuç«™ç‚¹çŠ¶æ€"""
def format_seconds(seconds: float) -> str:
    m, s = divmod(int(seconds), 60)
    return f"{m}åˆ†{s}ç§’"


async def fetch_shop_data(shop_name: str, logger) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, List[Dict]]:
    """
    æŠ“å–å•ä¸ªåº—é“ºçš„æ•°æ®

    Args:
        shop_name: åº—é“ºåç§°
        logger: æ—¥å¿—è®°å½•å™¨

    Returns:
        tuple: (è¿è§„æ•°æ®DataFrame, çŠ¶æ€æ•°æ®DataFrame, å¼‚å¸¸æ•°æ®DataFrame, goods_list)
    """
    skc_fetcher = SkcFetcher(shop_name,'temu_site')
    status_fetcher = SkuSiteStatusFetcher(shop_name,'temu_site')
    site_exception = SkuException(shop_name,'temu_site')

    # ========= 1ï¸âƒ£ è¿è§„æ•°æ® =========
    logger.info(f'æ­£åœ¨çˆ¬å–åº—é“º---{shop_name}---skc_sku_violateæ•°æ®')
    all_data = await skc_fetcher.fetch()

    violate_rows = all_data["violate_rows"]
    goods_list = all_data["goodsIdSkuIdPairList"]

    # å¦‚æœæ²¡æœ‰è¿è§„æ•°æ®ï¼Œè¿”å›ç©ºæ•°æ®
    if not violate_rows:
        logger.info(f'åº—é“º---{shop_name}---æ²¡æœ‰è¿è§„æ•°æ®')
        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), []

    df_violate = pd.DataFrame(violate_rows)

    # ========= 2ï¸âƒ£ ç«™ç‚¹çŠ¶æ€æ•°æ® =========
    logger.info(f'æ­£åœ¨çˆ¬å–åº—é“º---{shop_name}---sku_site_statusæ•°æ®')
    status_rows = []

    skc_seen = set()
    for item in violate_rows:
        skc_id = item["SKC"]
        if skc_id in skc_seen:
            continue
        skc_seen.add(skc_id)

        rows = await status_fetcher.fetch(skc_id)
        status_rows.extend(rows)

    df_status = pd.DataFrame(status_rows)

    # ========= 3ï¸âƒ£ å¼‚å¸¸æ•°æ® =========
    df_exception = pd.DataFrame()
    if goods_list:
        logger.info(f'æ­£åœ¨çˆ¬å–åº—é“º---{shop_name}---sku_site_exceptionæ•°æ®')
        exception_rows = await site_exception.fetch(goods_list)
        df_exception = pd.DataFrame(exception_rows)
    else:
        logger.info(f'åº—é“º---{shop_name}---goods_listä¸ºç©ºï¼Œè·³è¿‡å¼‚å¸¸æ•°æ®çˆ¬å–')

    return df_violate, df_status, df_exception, goods_list


def process_shop_data(
        shop_name: str,
        df_violate: pd.DataFrame,
        df_status: pd.DataFrame,
        df_exception: pd.DataFrame,
        goods_list: List[Dict]
):
    """
    å¤„ç†å•ä¸ªåº—é“ºçš„æ•°æ®

    Args:
        shop_name: åº—é“ºåç§°
        df_violate: è¿è§„æ•°æ®
        df_status: çŠ¶æ€æ•°æ®
        df_exception: å¼‚å¸¸æ•°æ®
        goods_list: å•†å“åˆ—è¡¨

    Returns:
        pd.DataFrame: å¤„ç†åçš„æœ€ç»ˆæ•°æ®
    """
    # ========= 1ï¸âƒ£ æ•°æ®æ ‡å‡†åŒ– =========
    df_status[['SKU', 'ç«™ç‚¹', 'åŠ ç«™çŠ¶æ€']] = df_status[['SKU', 'ç«™ç‚¹', 'åŠ ç«™çŠ¶æ€']]

    # ========= 2ï¸âƒ£ å¼‚å¸¸æ•°æ®å¤„ç† =========
    if not df_exception.empty and not df_violate.empty:
        # ç”¨ violation ç»™ exception è¡¥ SKU
        df_exception = df_exception.merge(
            df_violate[['skuId', 'SKU']].drop_duplicates(),
            how='left',
            on='skuId'
        )
    elif df_exception.empty:
        # åˆ›å»ºä¸€ä¸ªç©ºçš„å¼‚å¸¸æ•°æ®æ¡†
        df_exception = pd.DataFrame(columns=['SKU', 'ç«™ç‚¹', 'å¼‚å¸¸åŸå› ', 'skuId'])

    # ========= 3ï¸âƒ£ åˆå¹¶ä¸‰å¼ è¡¨ =========
    # é¦–å…ˆåˆå¹¶çŠ¶æ€å’Œè¿è§„æ•°æ®
    if not df_status.empty and not df_violate.empty:
        df = df_status.merge(
            df_violate[['SKC', 'SKU', 'ç«™ç‚¹', 'è¿è§„åŸå› ']],
            how='left',
            on=['SKU', 'ç«™ç‚¹']
        )
    else:
        df = pd.DataFrame()

    # å¦‚æœæœ‰å¼‚å¸¸æ•°æ®ï¼Œå†åˆå¹¶å¼‚å¸¸æ•°æ®
    if not df.empty and not df_exception.empty:
        df = df.merge(
            df_exception[['SKU', 'ç«™ç‚¹', 'å¼‚å¸¸åŸå› ']],
            how='left',
            on=['SKU', 'ç«™ç‚¹']
        )
    elif not df.empty:
        # å¦‚æœæ²¡æœ‰å¼‚å¸¸æ•°æ®ï¼Œæ·»åŠ ç©ºåˆ—
        df['å¼‚å¸¸åŸå› '] = pd.NA

    # ========= 4ï¸âƒ£ è¡¥å…¨ SKC =========
    if not df.empty and not df_violate.empty:
        df = df.merge(
            df_violate[['SKU', 'SKC']].drop_duplicates(),
            how='left',
            on='SKU',
            suffixes=('', '_violate')
        )
        df['SKC'] = df['SKC'].fillna(df['SKC_violate'])
        if 'SKC_violate' in df.columns:
            df.drop(columns=['SKC_violate'], inplace=True)

    # ========= 5ï¸âƒ£ åˆå¹¶è§„åˆ™å¤„ç† =========
    if not df.empty:
        df[['è¿è§„åŸå› ', 'å¼‚å¸¸åŸå› ']] = df[['è¿è§„åŸå› ', 'å¼‚å¸¸åŸå› ']].replace('', pd.NA)

        # è·å–å½“å‰å¤„ç†æ—¶é—´æˆ³ï¼ˆåœ¨åˆ†ç»„å‰ï¼‰
        process_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

        final_df = (
            df
            .groupby(
                ['SKC', 'SKU', 'åŠ ç«™çŠ¶æ€', 'è¿è§„åŸå› ', 'å¼‚å¸¸åŸå› '],
                dropna=False
            )['ç«™ç‚¹']
            .apply(lambda x: ','.join(sorted(set(x))))
            .reset_index()
        )

        final_df[['è¿è§„åŸå› ', 'å¼‚å¸¸åŸå› ']] = final_df[['è¿è§„åŸå› ', 'å¼‚å¸¸åŸå› ']].fillna('')

        # ========= æ–°å¢å¤„ç†æ—¶é—´åˆ— =========
        final_df.insert(0, 'æŠ“å–æ—¶é—´', process_time)  # æ’å…¥åˆ°ç¬¬ä¸€åˆ—

        # ========= æ–°å¢åº—é“ºåˆ— =========
        final_df.insert(1, 'åº—é“º', shop_name)  # æ’å…¥åˆ°ç¬¬äºŒåˆ—ï¼ˆåœ¨æ—¶é—´åˆ—åé¢ï¼‰

        # åˆ—é¡ºåºï¼ˆå¯è¯»æ€§æ›´å¥½ï¼‰
        output_file = SITE_DIR / f"{shop_name}_ç«™ç‚¹åŠ ç«™æœ€ç»ˆç»“æœ_{datetime.now():%Y%m%d}.xlsx"
        final_df.to_excel(output_file, index=False)


def prepare_upload_records(date) -> List[Dict]:
    """
    å‡†å¤‡ä¸Šä¼ æ•°æ®

    Args:
        date: æ—¥æœŸå­—ç¬¦ä¸²

    Returns:
        List[Dict]: ä¸Šä¼ è®°å½•åˆ—è¡¨
    """
    records = []

    SITE_DIR = Path(__file__).resolve().parent.parent / "data" / "site"
    pattern = f"*{date}.xlsx"
    files = list(SITE_DIR.glob(pattern))

    if not files:
        return records

    # è¯»å–Excelæ—¶å¼ºåˆ¶æ‰€æœ‰åˆ—ä¸ºå­—ç¬¦ä¸²ï¼Œå¹¶ç¦ç”¨NaNå€¼
    df_list = [pd.read_excel(f, dtype=str, keep_default_na=False) for f in files]
    df = pd.concat(df_list, ignore_index=True)

    for _, row in df.iterrows():
        sites_str = ','.join([s.strip() for s in str(row.get('ç«™ç‚¹', '')).split(',') if s.strip()])

        record = {
            "åº—é“º": str(row.get('åº—é“º', '')),
            "SKC": str(row.get('SKC', '')),
            "è´§å·": str(row.get('SKU', '')),
            "è¿è§„åŸå› ": [str(row['è¿è§„åŸå› '])] if row.get('è¿è§„åŸå› ') else [],
            "ç«™ç‚¹": sites_str,
            "å¼‚å¸¸åŸå› ": str(row.get('å¼‚å¸¸åŸå› ', '')),
            "åŠ ç«™çŠ¶æ€": str(row.get('åŠ ç«™çŠ¶æ€', '')),
            "æ•°æ®æŠ“å–æ—¥æœŸ": (row.get('æŠ“å–æ—¶é—´', ''))
        }
        records.append(record)

    return records



async def main():
    total_start = time.perf_counter()

    logger = get_logger('temu_site')

    config_yestody = {"base_id": "XPwkYGxZV3KRy1Gxfyb1E305VAgozOKL",
                      "sheet_id": "temuç«™ç‚¹çŠ¶æ€-æ˜¨å¤©",
                      "operator_id": "ZiSpuzyA49UNQz7CvPBUvhwiEiE"}
    logger.info('å¼€å§‹æ¸…é™¤æ˜¨å¤©æŠ¥è¡¨çš„æ•°æ®')
    # å…ˆæ¸…é™¤æ•°æ®
    test_delete_records(logger=logger, config=config_yestody)

    config = { "base_id": "XPwkYGxZV3KRy1Gxfyb1E305VAgozOKL",
               "sheet_id":"temuç«™ç‚¹çŠ¶æ€-å½“å¤©" ,
               "operator_id": "ZiSpuzyA49UNQz7CvPBUvhwiEiE" }

    logger.info('å¼€å§‹æ¸…é™¤ä»Šå¤©æŠ¥è¡¨çš„æ•°æ®')
    # å…ˆæ¸…é™¤æ•°æ®
    # test_delete_records(logger=logger, config=config)

    shop_name_list = [
        "2106-Temuå…¨æ‰˜ç®¡", "2105-Temuå…¨æ‰˜ç®¡", "2108-Temuå…¨æ‰˜ç®¡",
        "2107-Temuå…¨æ‰˜ç®¡", "2102-Temuå…¨æ‰˜ç®¡",
        "1108-Temuå…¨æ‰˜ç®¡", "1107-Temuå…¨æ‰˜ç®¡", "1106-Temuå…¨æ‰˜ç®¡",
        "1105-Temuå…¨æ‰˜ç®¡", "2103-Temuå…¨æ‰˜ç®¡",
        "112-Temuå…¨æ‰˜ç®¡", "151-Temuå…¨æ‰˜ç®¡å®¶å±…",
        "1104-Temuå…¨æ‰˜ç®¡", "1102-Temuå…¨æ‰˜ç®¡",
        "1103-Temuå…¨æ‰˜ç®¡", "1101-Temuå…¨æ‰˜ç®¡",
        "2101-Temuå…¨æ‰˜ç®¡KA", "110-Temuå…¨æ‰˜ç®¡KA",
        "109-Temuå…¨æ‰˜ç®¡KA", "108-Temuå…¨æ‰˜ç®¡",
        "107-Temuå…¨æ‰˜ç®¡", "106-Temuå…¨æ‰˜ç®¡",
        "105-Temuå…¨æ‰˜ç®¡", "104-Temuå…¨æ‰˜ç®¡",
        "103-Temuå…¨æ‰˜ç®¡", "102-Temuå…¨æ‰˜ç®¡",
        "101-Temuå…¨æ‰˜ç®¡"
    ]
    # shop_name_list=["103-Temuå…¨æ‰˜ç®¡"]



    for shop_name in shop_name_list:
        try:
            # ========= 1ï¸âƒ£ æŠ“å–æ•°æ® =========
            df_violate, df_status, df_exception, goods_list = await fetch_shop_data(shop_name, logger)

            # å¦‚æœæ²¡æœ‰è¿è§„æ•°æ®ï¼Œè·³è¿‡è¿™ä¸ªåº—é“º
            if df_violate.empty:
                logger.info(f'åº—é“º---{shop_name}---æ²¡æœ‰è¿è§„æ•°æ®ï¼Œè·³è¿‡')
                continue

            # ========= 2ï¸âƒ£ å¤„ç†æ•°æ® =========
            final_df = process_shop_data(shop_name, df_violate, df_status, df_exception, goods_list)

            if final_df.empty:
                logger.info(f'åº—é“º---{shop_name}---å¤„ç†åæ•°æ®ä¸ºç©ºï¼Œè·³è¿‡')
                continue
        except Exception as e:
            logger.error(f'å¤„ç†åº—é“º {shop_name} æ—¶å‡ºé”™: {str(e)}')
            continue

    # ========= 3ï¸âƒ£ å‡†å¤‡ä¸Šä¼ æ•°æ® =========
    # yesterday = (datetime.now() - timedelta(days=1)).strftime("%Y%m%d")
    # date = datetime.now().strftime("%Y%m%d")
    #
    # yesterday_records = prepare_upload_records(yesterday)
    # upload_multiple_records(logger=logger, config=config_yestody, records=yesterday_records)
    #
    # records = prepare_upload_records(date)
    # upload_multiple_records(logger=logger, config=config, records=records)

    total_cost = time.perf_counter() - total_start
    logger.info(f"ğŸ¯ å…¨æµç¨‹å®Œæˆï¼Œæ€»è€—æ—¶ï¼š{format_seconds(total_cost)}")
    ding_bot_send('me','site_daily_jobä»»åŠ¡ç»“æŸ')


if __name__ == "__main__":
    asyncio.run(main())